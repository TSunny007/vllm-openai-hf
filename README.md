# hf-vllm-docker
 Docker image to serve a LLM on vLLM using Huggingface inference endpoints
 DockerHub [image](https://hub.docker.com/r/tsunkaraneni/vllm-openai-hf/)

Go to deploy a model on huggingface
<img width="1160" alt="Screenshot 2024-09-25 at 11 07 12 AM" src="https://github.com/user-attachments/assets/8bc9ab60-7906-477a-a433-4018b3bd2c50">



Use the image under advanced settings:
docker.io/tsunkaraneni/vllm-openai-hf:latest
<img width="869" alt="Screenshot 2024-09-25 at 11 09 31 AM" src="https://github.com/user-attachments/assets/7e87f15e-f16b-4e9c-a3bf-59bcc3a7909c">

Optionally set any vLLm env variables
<img width="1244" alt="Screenshot 2024-09-25 at 11 10 09 AM" src="https://github.com/user-attachments/assets/bf80cb46-2f12-4507-8981-a16979c333e8">
